{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1Z5R8a9ItS6"
      },
      "source": [
        "# 加载数据"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UexauhJkYUSD"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torch import nn, optim\n",
        "from torchvision.transforms import transforms\n",
        "from torchsummary import summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5FO539a4f0fg",
        "outputId": "7ab9028c-3327-4760-a5ca-9e232100e35e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mon Oct 18 06:22:47 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.74       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P0    28W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9wEu1XBYoad",
        "outputId": "f9e32b20-9dee-4911-b9c6-acff5fef249f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JUchCajxY4B5",
        "outputId": "6298658d-6519-4ea3-c046-03089f14a6e8"
      },
      "outputs": [],
      "source": [
        "# !unzip /content/drive/MyDrive/Data.zip\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "atzprd0Gypo5",
        "outputId": "45d5cd42-6518-422b-bb39-b66e0e40e3b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1534\n",
            "384\n"
          ]
        }
      ],
      "source": [
        "!ls /content/drive/MyDrive/Data/data/train -l | grep \"^-\" | wc -l\n",
        "!ls /content/drive/MyDrive/Data/data/test -l | grep \"^-\" | wc -l"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7dPJyWlYUSG",
        "outputId": "fcbad53a-1105-4880-d572-3acb825b6df8"
      },
      "outputs": [],
      "source": [
        "%cd /content\n",
        "if os.path.exists(\"Ultrasound\"):\n",
        "    %rm -rf Ultrasound\n",
        "!ls\n",
        "if not os.path.exists(\"Ultrasound\"):\n",
        "    !git clone https://github.com/z872845991/Ultrasound.git\n",
        "%cd Ultrasound\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TeVP0bjqYUSH",
        "outputId": "d1daca53-d441-47fd-c3a3-8acc5595a2f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7rK0vWwTLRA"
      },
      "source": [
        "# 参数"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DCNKYZQrYUSJ"
      },
      "outputs": [],
      "source": [
        "from dataset.Fetus import FetusDataset\n",
        "from model.unet_res_myself_pool_connect_o_C import Unet_res_myself_pool\n",
        "from model.unet import Unet\n",
        "from model.idea3 import Idea3\n",
        "from tools.metrics import dice_coef,iou_score,get_accuracy,get_precision,get_specificity,get_recall,get_F1\n",
        "from tools.utils import AverageMeter\n",
        "from train.train_unet_local import train_model_local\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i9EQMUgsYUSI"
      },
      "outputs": [],
      "source": [
        "num_epoch=81\n",
        "batch_size={'train':2,\n",
        "            'val':1\n",
        "            }\n",
        "train_path='/content/Data/data/train'\n",
        "val_path='/content/Data/data/test'\n",
        "#变换\n",
        "x_transforms = transforms.Compose([\n",
        "    transforms.Resize((512,512)),\n",
        "    # transforms.CenterCrop(512),\n",
        "    transforms.ToTensor()\n",
        "    # transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
        "])\n",
        "# mask只需要转换为tensor\n",
        "y_transforms = transforms.Compose([\n",
        "    transforms.Resize((512, 512)),\n",
        "    # transforms.CenterCrop(512),\n",
        "    transforms.ToTensor()\n",
        "   ])\n",
        "#加载数据集\n",
        "train_dataset=FetusDataset(train_path,transform=x_transforms,target_transform=y_transforms)\n",
        "val_dataset=FetusDataset(val_path,transform=x_transforms,target_transform=y_transforms)\n",
        "#设置dataloader\n",
        "dataloaders={\n",
        "    'train':DataLoader(train_dataset,batch_size=batch_size['train'],shuffle=True,num_workers=0),\n",
        "    'val':DataLoader(val_dataset,batch_size=batch_size['val'],shuffle=True,num_workers=0)\n",
        "             }\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-Fv7mlxGIRV"
      },
      "source": [
        "# 训练"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrn2xS7JH-Bx"
      },
      "source": [
        "## 模型数据1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0-pMw_yYUSL",
        "outputId": "7676d319-a050-43fc-cdb5-e396064ad470"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 224, 224]           1,792\n",
            "       BatchNorm2d-2         [-1, 64, 224, 224]             128\n",
            "              ReLU-3         [-1, 64, 224, 224]               0\n",
            "            Conv2d-4         [-1, 64, 224, 224]          36,928\n",
            "       BatchNorm2d-5         [-1, 64, 224, 224]             128\n",
            "              ReLU-6         [-1, 64, 224, 224]               0\n",
            "         MaxPool2d-7         [-1, 64, 112, 112]               0\n",
            "            Conv2d-8        [-1, 128, 112, 112]          73,856\n",
            "       BatchNorm2d-9        [-1, 128, 112, 112]             256\n",
            "             ReLU-10        [-1, 128, 112, 112]               0\n",
            "           Conv2d-11        [-1, 128, 112, 112]         147,584\n",
            "      BatchNorm2d-12        [-1, 128, 112, 112]             256\n",
            "             ReLU-13        [-1, 128, 112, 112]               0\n",
            "        MaxPool2d-14          [-1, 128, 56, 56]               0\n",
            "           Conv2d-15          [-1, 256, 56, 56]         295,168\n",
            "      BatchNorm2d-16          [-1, 256, 56, 56]             512\n",
            "             ReLU-17          [-1, 256, 56, 56]               0\n",
            "           Conv2d-18          [-1, 256, 56, 56]         590,080\n",
            "      BatchNorm2d-19          [-1, 256, 56, 56]             512\n",
            "             ReLU-20          [-1, 256, 56, 56]               0\n",
            "        MaxPool2d-21          [-1, 256, 28, 28]               0\n",
            "           Conv2d-22          [-1, 512, 28, 28]       1,180,160\n",
            "      BatchNorm2d-23          [-1, 512, 28, 28]           1,024\n",
            "             ReLU-24          [-1, 512, 28, 28]               0\n",
            "           Conv2d-25          [-1, 512, 28, 28]       2,359,808\n",
            "      BatchNorm2d-26          [-1, 512, 28, 28]           1,024\n",
            "             ReLU-27          [-1, 512, 28, 28]               0\n",
            "        MaxPool2d-28          [-1, 512, 14, 14]               0\n",
            "           Conv2d-29          [-1, 512, 14, 14]         262,656\n",
            "      BatchNorm2d-30          [-1, 512, 14, 14]           1,024\n",
            "             ReLU-31          [-1, 512, 14, 14]               0\n",
            "           Conv2d-32          [-1, 512, 14, 14]       2,359,808\n",
            "      BatchNorm2d-33          [-1, 512, 14, 14]           1,024\n",
            "             ReLU-34          [-1, 512, 14, 14]               0\n",
            "           Conv2d-35          [-1, 512, 14, 14]       2,359,808\n",
            "      BatchNorm2d-36          [-1, 512, 14, 14]           1,024\n",
            "             ReLU-37          [-1, 512, 14, 14]               0\n",
            "           Conv2d-38          [-1, 512, 14, 14]       2,359,808\n",
            "      BatchNorm2d-39          [-1, 512, 14, 14]           1,024\n",
            "             ReLU-40          [-1, 512, 14, 14]               0\n",
            "           Conv2d-41          [-1, 512, 14, 14]       2,359,808\n",
            "      BatchNorm2d-42          [-1, 512, 14, 14]           1,024\n",
            "             ReLU-43          [-1, 512, 14, 14]               0\n",
            "           Conv2d-44          [-1, 512, 14, 14]       2,359,808\n",
            "      BatchNorm2d-45          [-1, 512, 14, 14]           1,024\n",
            "             ReLU-46          [-1, 512, 14, 14]               0\n",
            "           Conv2d-47          [-1, 512, 14, 14]       2,359,808\n",
            "      BatchNorm2d-48          [-1, 512, 14, 14]           1,024\n",
            "             ReLU-49          [-1, 512, 14, 14]               0\n",
            "           Conv2d-50         [-1, 1024, 14, 14]      14,156,800\n",
            "      BatchNorm2d-51         [-1, 1024, 14, 14]           2,048\n",
            "             ReLU-52         [-1, 1024, 14, 14]               0\n",
            "Incpetion_dense_block_1-53         [-1, 1024, 14, 14]               0\n",
            "  ConvTranspose2d-54          [-1, 512, 28, 28]       2,097,664\n",
            "           Conv2d-55          [-1, 512, 28, 28]       4,719,104\n",
            "      BatchNorm2d-56          [-1, 512, 28, 28]           1,024\n",
            "             ReLU-57          [-1, 512, 28, 28]               0\n",
            "           Conv2d-58          [-1, 512, 28, 28]       2,359,808\n",
            "      BatchNorm2d-59          [-1, 512, 28, 28]           1,024\n",
            "             ReLU-60          [-1, 512, 28, 28]               0\n",
            "  ConvTranspose2d-61          [-1, 256, 56, 56]         524,544\n",
            "           Conv2d-62          [-1, 256, 56, 56]       1,179,904\n",
            "      BatchNorm2d-63          [-1, 256, 56, 56]             512\n",
            "             ReLU-64          [-1, 256, 56, 56]               0\n",
            "           Conv2d-65          [-1, 256, 56, 56]         590,080\n",
            "      BatchNorm2d-66          [-1, 256, 56, 56]             512\n",
            "             ReLU-67          [-1, 256, 56, 56]               0\n",
            "  ConvTranspose2d-68        [-1, 128, 112, 112]         131,200\n",
            "           Conv2d-69        [-1, 128, 112, 112]         295,040\n",
            "      BatchNorm2d-70        [-1, 128, 112, 112]             256\n",
            "             ReLU-71        [-1, 128, 112, 112]               0\n",
            "           Conv2d-72        [-1, 128, 112, 112]         147,584\n",
            "      BatchNorm2d-73        [-1, 128, 112, 112]             256\n",
            "             ReLU-74        [-1, 128, 112, 112]               0\n",
            "  ConvTranspose2d-75         [-1, 64, 224, 224]          32,832\n",
            "           Conv2d-76         [-1, 64, 224, 224]          73,792\n",
            "      BatchNorm2d-77         [-1, 64, 224, 224]             128\n",
            "             ReLU-78         [-1, 64, 224, 224]               0\n",
            "           Conv2d-79         [-1, 64, 224, 224]          36,928\n",
            "      BatchNorm2d-80         [-1, 64, 224, 224]             128\n",
            "             ReLU-81         [-1, 64, 224, 224]               0\n",
            "           Conv2d-82          [-1, 1, 224, 224]              65\n",
            "================================================================\n",
            "Total params: 45,469,121\n",
            "Trainable params: 45,469,121\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 631.26\n",
            "Params size (MB): 173.45\n",
            "Estimated Total Size (MB): 805.28\n",
            "----------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ]
        }
      ],
      "source": [
        "model=Idea3(n_class=1)\n",
        "#model=Unet(n_class=1)\n",
        "model.to(device)\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "train=train_model_local(model)\n",
        "train.summarys(input_size=(3,224,224))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q7PYcgxPIk99"
      },
      "outputs": [],
      "source": [
        "train.compile(dataloaders,criterion,optimizer,num_epoch,batch_size,train_path,val_path,device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "50tP7L4KI4dy"
      },
      "outputs": [],
      "source": [
        "file1='/content/drive/MyDrive/result/train/train_7m_Idea3_change.txt'\n",
        "file2='/content/drive/MyDrive/result/test/test_7m_Idea3_change.txt'\n",
        "path1='/content/drive/MyDrive/result/checkpoins/train_7m_Idea3'\n",
        "train.fit(file1,file2,path1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pic1=next(iter(dataloaders['val']))\n",
        "pth1=model.load_state_dict(torch.load(os.path.join(path1,'_%d.pth'%(num_epoch-1)))).to(device)\n",
        "y=pth1(pic1).cpu()\n",
        "img1_y=torch.squeeze(y).numpy()\n",
        "plt.imshow(img1_y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Z63M3uHGLP7"
      },
      "source": [
        "## 模型数据2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UV3FTecfGQJM",
        "outputId": "5da77860-66c6-48c3-a63b-9ae7cf165ece"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 224, 224]             256\n",
            "       BatchNorm2d-2         [-1, 64, 224, 224]             128\n",
            "              ReLU-3         [-1, 64, 224, 224]               0\n",
            "            Conv2d-4         [-1, 64, 224, 224]          36,928\n",
            "       BatchNorm2d-5         [-1, 64, 224, 224]             128\n",
            "              ReLU-6         [-1, 64, 224, 224]               0\n",
            "            Conv2d-7         [-1, 64, 224, 224]          36,928\n",
            "       BatchNorm2d-8         [-1, 64, 224, 224]             128\n",
            "              ReLU-9         [-1, 64, 224, 224]               0\n",
            "        MaxPool2d-10         [-1, 64, 112, 112]               0\n",
            "        MaxPool2d-11         [-1, 64, 112, 112]               0\n",
            "           Conv2d-12        [-1, 128, 112, 112]           8,320\n",
            "      BatchNorm2d-13        [-1, 128, 112, 112]             256\n",
            "             ReLU-14        [-1, 128, 112, 112]               0\n",
            "           Conv2d-15        [-1, 128, 112, 112]         221,312\n",
            "      BatchNorm2d-16        [-1, 128, 112, 112]             256\n",
            "             ReLU-17        [-1, 128, 112, 112]               0\n",
            "           Conv2d-18        [-1, 128, 112, 112]         147,584\n",
            "      BatchNorm2d-19        [-1, 128, 112, 112]             256\n",
            "             ReLU-20        [-1, 128, 112, 112]               0\n",
            "        MaxPool2d-21          [-1, 128, 56, 56]               0\n",
            "        MaxPool2d-22          [-1, 128, 56, 56]               0\n",
            "           Conv2d-23          [-1, 256, 56, 56]          33,024\n",
            "      BatchNorm2d-24          [-1, 256, 56, 56]             512\n",
            "             ReLU-25          [-1, 256, 56, 56]               0\n",
            "           Conv2d-26          [-1, 256, 56, 56]         884,992\n",
            "      BatchNorm2d-27          [-1, 256, 56, 56]             512\n",
            "             ReLU-28          [-1, 256, 56, 56]               0\n",
            "           Conv2d-29          [-1, 256, 56, 56]         590,080\n",
            "      BatchNorm2d-30          [-1, 256, 56, 56]             512\n",
            "             ReLU-31          [-1, 256, 56, 56]               0\n",
            "        MaxPool2d-32          [-1, 256, 28, 28]               0\n",
            "        MaxPool2d-33          [-1, 256, 28, 28]               0\n",
            "           Conv2d-34          [-1, 512, 28, 28]         131,584\n",
            "      BatchNorm2d-35          [-1, 512, 28, 28]           1,024\n",
            "             ReLU-36          [-1, 512, 28, 28]               0\n",
            "           Conv2d-37          [-1, 512, 28, 28]       3,539,456\n",
            "      BatchNorm2d-38          [-1, 512, 28, 28]           1,024\n",
            "             ReLU-39          [-1, 512, 28, 28]               0\n",
            "           Conv2d-40          [-1, 512, 28, 28]       2,359,808\n",
            "      BatchNorm2d-41          [-1, 512, 28, 28]           1,024\n",
            "             ReLU-42          [-1, 512, 28, 28]               0\n",
            "        MaxPool2d-43          [-1, 512, 14, 14]               0\n",
            "           Conv2d-44         [-1, 1024, 14, 14]       4,719,616\n",
            "      BatchNorm2d-45         [-1, 1024, 14, 14]           2,048\n",
            "             ReLU-46         [-1, 1024, 14, 14]               0\n",
            "           Conv2d-47         [-1, 1024, 14, 14]       9,438,208\n",
            "      BatchNorm2d-48         [-1, 1024, 14, 14]           2,048\n",
            "             ReLU-49         [-1, 1024, 14, 14]               0\n",
            "  ConvTranspose2d-50          [-1, 512, 28, 28]       2,097,664\n",
            "           Conv2d-51          [-1, 512, 28, 28]       4,719,104\n",
            "      BatchNorm2d-52          [-1, 512, 28, 28]           1,024\n",
            "             ReLU-53          [-1, 512, 28, 28]               0\n",
            "           Conv2d-54          [-1, 512, 28, 28]       2,359,808\n",
            "      BatchNorm2d-55          [-1, 512, 28, 28]           1,024\n",
            "             ReLU-56          [-1, 512, 28, 28]               0\n",
            "  ConvTranspose2d-57          [-1, 256, 56, 56]         524,544\n",
            "           Conv2d-58          [-1, 256, 56, 56]       1,179,904\n",
            "      BatchNorm2d-59          [-1, 256, 56, 56]             512\n",
            "             ReLU-60          [-1, 256, 56, 56]               0\n",
            "           Conv2d-61          [-1, 256, 56, 56]         590,080\n",
            "      BatchNorm2d-62          [-1, 256, 56, 56]             512\n",
            "             ReLU-63          [-1, 256, 56, 56]               0\n",
            "  ConvTranspose2d-64        [-1, 128, 112, 112]         131,200\n",
            "           Conv2d-65        [-1, 128, 112, 112]         295,040\n",
            "      BatchNorm2d-66        [-1, 128, 112, 112]             256\n",
            "             ReLU-67        [-1, 128, 112, 112]               0\n",
            "           Conv2d-68        [-1, 128, 112, 112]         147,584\n",
            "      BatchNorm2d-69        [-1, 128, 112, 112]             256\n",
            "             ReLU-70        [-1, 128, 112, 112]               0\n",
            "  ConvTranspose2d-71         [-1, 64, 224, 224]          32,832\n",
            "           Conv2d-72         [-1, 64, 224, 224]          73,792\n",
            "      BatchNorm2d-73         [-1, 64, 224, 224]             128\n",
            "             ReLU-74         [-1, 64, 224, 224]               0\n",
            "           Conv2d-75         [-1, 64, 224, 224]          36,928\n",
            "      BatchNorm2d-76         [-1, 64, 224, 224]             128\n",
            "             ReLU-77         [-1, 64, 224, 224]               0\n",
            "           Conv2d-78          [-1, 1, 224, 224]              65\n",
            "================================================================\n",
            "Total params: 34,350,337\n",
            "Trainable params: 34,350,337\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 766.77\n",
            "Params size (MB): 131.04\n",
            "Estimated Total Size (MB): 898.38\n",
            "----------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ]
        }
      ],
      "source": [
        "model2=Unet_res_myself_pool(n_class=1)\n",
        "#model=Unet(n_class=1)\n",
        "model2.to(device)\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model2.parameters())\n",
        "\n",
        "train2=train_model_local(model2)\n",
        "train2.summarys(input_size=(3,224,224))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DHaXIjhsGmCC"
      },
      "outputs": [],
      "source": [
        "train2.compile(dataloaders,criterion,optimizer,num_epoch,batch_size,train_path,val_path,device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eHKYyQxJGo9J",
        "outputId": "842d30fb-bb51-4019-f0c0-e40ce9db7338"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train \t epoch: 0  ,idx: 383   ,loss: 0.138   ,miou:   0.039,maxiou: 0.560    ,miniou: 0.000    ,mdice: 0.114   ,maxdice: 0.353   ,mindice: 0.018   \n",
            "\n",
            "val \t epoch: 0  ,idx: 191   ,miou:   0.002,maxiou: 0.345    ,miniou: 0.000    ,mdice: 0.030   ,maxdice: 0.335   ,mindice: 0.002   \n",
            "\n",
            "train \t epoch: 1  ,idx: 383   ,loss: 0.047   ,miou:   0.311,maxiou: 0.782    ,miniou: 0.000    ,mdice: 0.358   ,maxdice: 0.729   ,mindice: 0.019   \n",
            "\n",
            "val \t epoch: 1  ,idx: 191   ,miou:   0.006,maxiou: 0.618    ,miniou: 0.000    ,mdice: 0.035   ,maxdice: 0.594   ,mindice: 0.002   \n",
            "\n",
            "train \t epoch: 2  ,idx: 383   ,loss: 0.035   ,miou:   0.449,maxiou: 0.845    ,miniou: 0.000    ,mdice: 0.484   ,maxdice: 0.783   ,mindice: 0.010   \n",
            "\n",
            "val \t epoch: 2  ,idx: 191   ,miou:   0.001,maxiou: 0.197    ,miniou: 0.000    ,mdice: 0.028   ,maxdice: 0.233   ,mindice: 0.001   \n",
            "\n",
            "train \t epoch: 3  ,idx: 383   ,loss: 0.035   ,miou:   0.505,maxiou: 0.833    ,miniou: 0.000    ,mdice: 0.529   ,maxdice: 0.807   ,mindice: 0.003   \n",
            "\n",
            "val \t epoch: 3  ,idx: 191   ,miou:   0.204,maxiou: 0.822    ,miniou: 0.000    ,mdice: 0.293   ,maxdice: 0.726   ,mindice: 0.001   \n",
            "\n",
            "train \t epoch: 4  ,idx: 383   ,loss: 0.022   ,miou:   0.652,maxiou: 0.851    ,miniou: 0.140    ,mdice: 0.658   ,maxdice: 0.811   ,mindice: 0.259   \n",
            "\n",
            "val \t epoch: 4  ,idx: 191   ,miou:   0.483,maxiou: 0.877    ,miniou: 0.000    ,mdice: 0.522   ,maxdice: 0.836   ,mindice: 0.001   \n",
            "\n",
            "train \t epoch: 5  ,idx: 383   ,loss: 0.020   ,miou:   0.678,maxiou: 0.874    ,miniou: 0.203    ,mdice: 0.702   ,maxdice: 0.834   ,mindice: 0.307   \n",
            "\n",
            "val \t epoch: 5  ,idx: 191   ,miou:   0.144,maxiou: 0.863    ,miniou: 0.000    ,mdice: 0.432   ,maxdice: 0.844   ,mindice: 0.000   \n",
            "\n",
            "train \t epoch: 6  ,idx: 383   ,loss: 0.019   ,miou:   0.555,maxiou: 0.868    ,miniou: 0.000    ,mdice: 0.668   ,maxdice: 0.826   ,mindice: 0.343   \n",
            "\n",
            "val \t epoch: 6  ,idx: 191   ,miou:   0.587,maxiou: 0.896    ,miniou: 0.000    ,mdice: 0.618   ,maxdice: 0.873   ,mindice: 0.000   \n",
            "\n",
            "train \t epoch: 7  ,idx: 383   ,loss: 0.017   ,miou:   0.716,maxiou: 0.874    ,miniou: 0.284    ,mdice: 0.742   ,maxdice: 0.841   ,mindice: 0.419   \n",
            "\n",
            "val \t epoch: 7  ,idx: 191   ,miou:   0.647,maxiou: 0.898    ,miniou: 0.000    ,mdice: 0.678   ,maxdice: 0.887   ,mindice: 0.000   \n",
            "\n",
            "train \t epoch: 8  ,idx: 383   ,loss: 0.015   ,miou:   0.733,maxiou: 0.873    ,miniou: 0.208    ,mdice: 0.763   ,maxdice: 0.857   ,mindice: 0.317   \n",
            "\n",
            "val \t epoch: 8  ,idx: 191   ,miou:   0.617,maxiou: 0.906    ,miniou: 0.000    ,mdice: 0.659   ,maxdice: 0.892   ,mindice: 0.000   \n",
            "\n",
            "train \t epoch: 9  ,idx: 383   ,loss: 0.014   ,miou:   0.751,maxiou: 0.896    ,miniou: 0.375    ,mdice: 0.782   ,maxdice: 0.870   ,mindice: 0.500   \n",
            "\n",
            "val \t epoch: 9  ,idx: 191   ,miou:   0.687,maxiou: 0.899    ,miniou: 0.000    ,mdice: 0.719   ,maxdice: 0.895   ,mindice: 0.001   \n",
            "\n",
            "train \t epoch: 10  ,idx: 383   ,loss: 0.014   ,miou:   0.758,maxiou: 0.893    ,miniou: 0.465    ,mdice: 0.789   ,maxdice: 0.872   ,mindice: 0.544   \n",
            "\n",
            "val \t epoch: 10  ,idx: 191   ,miou:   0.145,maxiou: 0.895    ,miniou: 0.000    ,mdice: 0.488   ,maxdice: 0.893   ,mindice: 0.000   \n",
            "\n",
            "train \t epoch: 11  ,idx: 383   ,loss: 0.014   ,miou:   0.753,maxiou: 0.903    ,miniou: 0.161    ,mdice: 0.777   ,maxdice: 0.878   ,mindice: 0.380   \n",
            "\n",
            "val \t epoch: 11  ,idx: 191   ,miou:   0.712,maxiou: 0.906    ,miniou: 0.000    ,mdice: 0.748   ,maxdice: 0.901   ,mindice: 0.001   \n",
            "\n",
            "train \t epoch: 12  ,idx: 383   ,loss: 0.012   ,miou:   0.782,maxiou: 0.929    ,miniou: 0.433    ,mdice: 0.815   ,maxdice: 0.884   ,mindice: 0.570   \n",
            "\n",
            "val \t epoch: 12  ,idx: 191   ,miou:   0.726,maxiou: 0.912    ,miniou: 0.000    ,mdice: 0.768   ,maxdice: 0.904   ,mindice: 0.143   \n",
            "\n",
            "train \t epoch: 13  ,idx: 383   ,loss: 0.012   ,miou:   0.786,maxiou: 0.903    ,miniou: 0.303    ,mdice: 0.818   ,maxdice: 0.893   ,mindice: 0.369   \n",
            "\n",
            "val \t epoch: 13  ,idx: 191   ,miou:   0.663,maxiou: 0.921    ,miniou: 0.000    ,mdice: 0.584   ,maxdice: 0.907   ,mindice: 0.026   \n",
            "\n",
            "train \t epoch: 14  ,idx: 383   ,loss: 0.018   ,miou:   0.788,maxiou: 0.914    ,miniou: 0.396    ,mdice: 0.628   ,maxdice: 0.696   ,mindice: 0.365   \n",
            "\n",
            "val \t epoch: 14  ,idx: 191   ,miou:   0.777,maxiou: 0.918    ,miniou: 0.201    ,mdice: 0.660   ,maxdice: 0.729   ,mindice: 0.388   \n",
            "\n",
            "train \t epoch: 15  ,idx: 383   ,loss: 0.010   ,miou:   0.809,maxiou: 0.910    ,miniou: 0.520    ,mdice: 0.837   ,maxdice: 0.902   ,mindice: 0.635   \n",
            "\n",
            "val \t epoch: 15  ,idx: 191   ,miou:   0.687,maxiou: 0.917    ,miniou: 0.000    ,mdice: 0.670   ,maxdice: 0.906   ,mindice: 0.019   \n",
            "\n",
            "train \t epoch: 16  ,idx: 383   ,loss: 0.010   ,miou:   0.809,maxiou: 0.929    ,miniou: 0.454    ,mdice: 0.839   ,maxdice: 0.919   ,mindice: 0.551   \n",
            "\n",
            "val \t epoch: 16  ,idx: 191   ,miou:   0.783,maxiou: 0.939    ,miniou: 0.000    ,mdice: 0.820   ,maxdice: 0.927   ,mindice: 0.223   \n",
            "\n",
            "train \t epoch: 17  ,idx: 383   ,loss: 0.009   ,miou:   0.826,maxiou: 0.916    ,miniou: 0.527    ,mdice: 0.858   ,maxdice: 0.918   ,mindice: 0.670   \n",
            "\n",
            "val \t epoch: 17  ,idx: 191   ,miou:   0.751,maxiou: 0.909    ,miniou: 0.062    ,mdice: 0.787   ,maxdice: 0.919   ,mindice: 0.363   \n",
            "\n",
            "train \t epoch: 18  ,idx: 383   ,loss: 0.010   ,miou:   0.818,maxiou: 0.920    ,miniou: 0.374    ,mdice: 0.850   ,maxdice: 0.918   ,mindice: 0.509   \n",
            "\n",
            "val \t epoch: 18  ,idx: 191   ,miou:   0.825,maxiou: 0.931    ,miniou: 0.546    ,mdice: 0.860   ,maxdice: 0.920   ,mindice: 0.632   \n",
            "\n",
            "train \t epoch: 19  ,idx: 383   ,loss: 0.009   ,miou:   0.830,maxiou: 0.921    ,miniou: 0.363    ,mdice: 0.862   ,maxdice: 0.918   ,mindice: 0.518   \n",
            "\n",
            "val \t epoch: 19  ,idx: 191   ,miou:   0.723,maxiou: 0.930    ,miniou: 0.000    ,mdice: 0.754   ,maxdice: 0.916   ,mindice: 0.018   \n",
            "\n",
            "train \t epoch: 20  ,idx: 383   ,loss: 0.009   ,miou:   0.836,maxiou: 0.928    ,miniou: 0.407    ,mdice: 0.865   ,maxdice: 0.925   ,mindice: 0.620   \n",
            "\n",
            "val \t epoch: 20  ,idx: 191   ,miou:   0.844,maxiou: 0.931    ,miniou: 0.572    ,mdice: 0.876   ,maxdice: 0.926   ,mindice: 0.712   \n",
            "\n",
            "train \t epoch: 21  ,idx: 383   ,loss: 0.007   ,miou:   0.854,maxiou: 0.919    ,miniou: 0.632    ,mdice: 0.884   ,maxdice: 0.928   ,mindice: 0.693   \n",
            "\n",
            "val \t epoch: 21  ,idx: 191   ,miou:   0.792,maxiou: 0.936    ,miniou: 0.000    ,mdice: 0.809   ,maxdice: 0.949   ,mindice: 0.040   \n",
            "\n",
            "train \t epoch: 22  ,idx: 383   ,loss: 0.008   ,miou:   0.845,maxiou: 0.924    ,miniou: 0.494    ,mdice: 0.859   ,maxdice: 0.916   ,mindice: 0.587   \n",
            "\n",
            "val \t epoch: 22  ,idx: 191   ,miou:   0.842,maxiou: 0.943    ,miniou: 0.551    ,mdice: 0.878   ,maxdice: 0.937   ,mindice: 0.664   \n",
            "\n",
            "train \t epoch: 23  ,idx: 383   ,loss: 0.008   ,miou:   0.849,maxiou: 0.928    ,miniou: 0.656    ,mdice: 0.879   ,maxdice: 0.922   ,mindice: 0.740   \n",
            "\n",
            "val \t epoch: 23  ,idx: 191   ,miou:   0.856,maxiou: 0.946    ,miniou: 0.624    ,mdice: 0.887   ,maxdice: 0.940   ,mindice: 0.683   \n",
            "\n",
            "train \t epoch: 24  ,idx: 383   ,loss: 0.007   ,miou:   0.863,maxiou: 0.928    ,miniou: 0.693    ,mdice: 0.892   ,maxdice: 0.931   ,mindice: 0.798   \n",
            "\n",
            "val \t epoch: 24  ,idx: 191   ,miou:   0.860,maxiou: 0.942    ,miniou: 0.647    ,mdice: 0.890   ,maxdice: 0.934   ,mindice: 0.774   \n",
            "\n",
            "train \t epoch: 25  ,idx: 383   ,loss: 0.007   ,miou:   0.860,maxiou: 0.932    ,miniou: 0.624    ,mdice: 0.890   ,maxdice: 0.928   ,mindice: 0.708   \n",
            "\n",
            "val \t epoch: 25  ,idx: 191   ,miou:   0.870,maxiou: 0.943    ,miniou: 0.694    ,mdice: 0.900   ,maxdice: 0.947   ,mindice: 0.798   \n",
            "\n",
            "train \t epoch: 26  ,idx: 383   ,loss: 0.006   ,miou:   0.868,maxiou: 0.929    ,miniou: 0.745    ,mdice: 0.897   ,maxdice: 0.935   ,mindice: 0.829   \n",
            "\n",
            "val \t epoch: 26  ,idx: 191   ,miou:   0.819,maxiou: 0.928    ,miniou: 0.000    ,mdice: 0.851   ,maxdice: 0.941   ,mindice: 0.004   \n",
            "\n",
            "train \t epoch: 27  ,idx: 383   ,loss: 0.008   ,miou:   0.851,maxiou: 0.923    ,miniou: 0.614    ,mdice: 0.879   ,maxdice: 0.923   ,mindice: 0.711   \n",
            "\n",
            "val \t epoch: 27  ,idx: 191   ,miou:   0.866,maxiou: 0.942    ,miniou: 0.531    ,mdice: 0.897   ,maxdice: 0.940   ,mindice: 0.668   \n",
            "\n",
            "train \t epoch: 28  ,idx: 383   ,loss: 0.007   ,miou:   0.862,maxiou: 0.930    ,miniou: 0.605    ,mdice: 0.890   ,maxdice: 0.930   ,mindice: 0.696   \n",
            "\n",
            "val \t epoch: 28  ,idx: 191   ,miou:   0.879,maxiou: 0.953    ,miniou: 0.686    ,mdice: 0.906   ,maxdice: 0.949   ,mindice: 0.806   \n",
            "\n",
            "train \t epoch: 29  ,idx: 383   ,loss: 0.006   ,miou:   0.876,maxiou: 0.935    ,miniou: 0.703    ,mdice: 0.903   ,maxdice: 0.932   ,mindice: 0.805   \n",
            "\n",
            "val \t epoch: 29  ,idx: 191   ,miou:   0.772,maxiou: 0.942    ,miniou: 0.000    ,mdice: 0.808   ,maxdice: 0.938   ,mindice: 0.015   \n",
            "\n",
            "train \t epoch: 30  ,idx: 383   ,loss: 0.007   ,miou:   0.865,maxiou: 0.932    ,miniou: 0.617    ,mdice: 0.893   ,maxdice: 0.931   ,mindice: 0.723   \n",
            "\n",
            "val \t epoch: 30  ,idx: 191   ,miou:   0.867,maxiou: 0.938    ,miniou: 0.433    ,mdice: 0.897   ,maxdice: 0.946   ,mindice: 0.586   \n",
            "\n",
            "train \t epoch: 31  ,idx: 383   ,loss: 0.006   ,miou:   0.878,maxiou: 0.929    ,miniou: 0.729    ,mdice: 0.905   ,maxdice: 0.938   ,mindice: 0.793   \n",
            "\n",
            "val \t epoch: 31  ,idx: 191   ,miou:   0.816,maxiou: 0.929    ,miniou: 0.042    ,mdice: 0.845   ,maxdice: 0.935   ,mindice: 0.188   \n",
            "\n",
            "train \t epoch: 32  ,idx: 383   ,loss: 0.006   ,miou:   0.868,maxiou: 0.929    ,miniou: 0.590    ,mdice: 0.897   ,maxdice: 0.936   ,mindice: 0.723   \n",
            "\n",
            "val \t epoch: 32  ,idx: 191   ,miou:   0.879,maxiou: 0.948    ,miniou: 0.698    ,mdice: 0.908   ,maxdice: 0.951   ,mindice: 0.807   \n",
            "\n",
            "train \t epoch: 33  ,idx: 383   ,loss: 0.006   ,miou:   0.883,maxiou: 0.932    ,miniou: 0.732    ,mdice: 0.909   ,maxdice: 0.937   ,mindice: 0.817   \n",
            "\n",
            "val \t epoch: 33  ,idx: 191   ,miou:   0.890,maxiou: 0.953    ,miniou: 0.738    ,mdice: 0.916   ,maxdice: 0.955   ,mindice: 0.828   \n",
            "\n",
            "train \t epoch: 34  ,idx: 383   ,loss: 0.006   ,miou:   0.882,maxiou: 0.935    ,miniou: 0.550    ,mdice: 0.908   ,maxdice: 0.941   ,mindice: 0.674   \n",
            "\n",
            "val \t epoch: 34  ,idx: 191   ,miou:   0.891,maxiou: 0.950    ,miniou: 0.775    ,mdice: 0.917   ,maxdice: 0.956   ,mindice: 0.854   \n",
            "\n",
            "train \t epoch: 35  ,idx: 383   ,loss: 0.005   ,miou:   0.885,maxiou: 0.933    ,miniou: 0.645    ,mdice: 0.912   ,maxdice: 0.940   ,mindice: 0.757   \n",
            "\n",
            "val \t epoch: 35  ,idx: 191   ,miou:   0.886,maxiou: 0.948    ,miniou: 0.000    ,mdice: 0.911   ,maxdice: 0.954   ,mindice: 0.145   \n",
            "\n",
            "train \t epoch: 36  ,idx: 383   ,loss: 0.006   ,miou:   0.882,maxiou: 0.934    ,miniou: 0.728    ,mdice: 0.909   ,maxdice: 0.937   ,mindice: 0.795   \n",
            "\n",
            "val \t epoch: 36  ,idx: 191   ,miou:   0.890,maxiou: 0.942    ,miniou: 0.753    ,mdice: 0.916   ,maxdice: 0.948   ,mindice: 0.834   \n",
            "\n",
            "train \t epoch: 37  ,idx: 383   ,loss: 0.005   ,miou:   0.889,maxiou: 0.938    ,miniou: 0.771    ,mdice: 0.914   ,maxdice: 0.943   ,mindice: 0.826   \n",
            "\n",
            "val \t epoch: 37  ,idx: 191   ,miou:   0.893,maxiou: 0.951    ,miniou: 0.797    ,mdice: 0.919   ,maxdice: 0.953   ,mindice: 0.862   \n",
            "\n",
            "train \t epoch: 38  ,idx: 383   ,loss: 0.006   ,miou:   0.883,maxiou: 0.941    ,miniou: 0.536    ,mdice: 0.910   ,maxdice: 0.940   ,mindice: 0.722   \n",
            "\n",
            "val \t epoch: 38  ,idx: 191   ,miou:   0.767,maxiou: 0.947    ,miniou: 0.000    ,mdice: 0.794   ,maxdice: 0.944   ,mindice: 0.020   \n",
            "\n",
            "train \t epoch: 39  ,idx: 383   ,loss: 0.006   ,miou:   0.881,maxiou: 0.941    ,miniou: 0.725    ,mdice: 0.906   ,maxdice: 0.942   ,mindice: 0.796   \n",
            "\n",
            "val \t epoch: 39  ,idx: 191   ,miou:   0.896,maxiou: 0.949    ,miniou: 0.791    ,mdice: 0.921   ,maxdice: 0.953   ,mindice: 0.852   \n",
            "\n",
            "train \t epoch: 40  ,idx: 383   ,loss: 0.005   ,miou:   0.896,maxiou: 0.938    ,miniou: 0.792    ,mdice: 0.920   ,maxdice: 0.941   ,mindice: 0.847   \n",
            "\n",
            "val \t epoch: 40  ,idx: 191   ,miou:   0.903,maxiou: 0.954    ,miniou: 0.789    ,mdice: 0.927   ,maxdice: 0.955   ,mindice: 0.865   \n",
            "\n",
            "train \t epoch: 41  ,idx: 383   ,loss: 0.005   ,miou:   0.901,maxiou: 0.938    ,miniou: 0.801    ,mdice: 0.924   ,maxdice: 0.948   ,mindice: 0.867   \n",
            "\n",
            "val \t epoch: 41  ,idx: 191   ,miou:   0.909,maxiou: 0.949    ,miniou: 0.811    ,mdice: 0.931   ,maxdice: 0.955   ,mindice: 0.880   \n",
            "\n",
            "train \t epoch: 42  ,idx: 383   ,loss: 0.005   ,miou:   0.902,maxiou: 0.943    ,miniou: 0.822    ,mdice: 0.925   ,maxdice: 0.947   ,mindice: 0.883   \n",
            "\n",
            "val \t epoch: 42  ,idx: 191   ,miou:   0.910,maxiou: 0.953    ,miniou: 0.818    ,mdice: 0.932   ,maxdice: 0.957   ,mindice: 0.880   \n",
            "\n",
            "train \t epoch: 43  ,idx: 383   ,loss: 0.005   ,miou:   0.903,maxiou: 0.949    ,miniou: 0.799    ,mdice: 0.926   ,maxdice: 0.948   ,mindice: 0.873   \n",
            "\n",
            "val \t epoch: 43  ,idx: 191   ,miou:   0.767,maxiou: 0.939    ,miniou: 0.000    ,mdice: 0.802   ,maxdice: 0.952   ,mindice: 0.043   \n",
            "\n",
            "train \t epoch: 44  ,idx: 383   ,loss: 0.006   ,miou:   0.884,maxiou: 0.942    ,miniou: 0.621    ,mdice: 0.910   ,maxdice: 0.950   ,mindice: 0.737   \n",
            "\n",
            "val \t epoch: 44  ,idx: 191   ,miou:   0.910,maxiou: 0.957    ,miniou: 0.803    ,mdice: 0.931   ,maxdice: 0.957   ,mindice: 0.871   \n",
            "\n",
            "train \t epoch: 45  ,idx: 383   ,loss: 0.004   ,miou:   0.906,maxiou: 0.945    ,miniou: 0.825    ,mdice: 0.929   ,maxdice: 0.948   ,mindice: 0.890   \n",
            "\n",
            "val \t epoch: 45  ,idx: 191   ,miou:   0.917,maxiou: 0.958    ,miniou: 0.851    ,mdice: 0.936   ,maxdice: 0.962   ,mindice: 0.900   \n",
            "\n",
            "train \t epoch: 46  ,idx: 383   ,loss: 0.004   ,miou:   0.909,maxiou: 0.949    ,miniou: 0.765    ,mdice: 0.931   ,maxdice: 0.952   ,mindice: 0.815   \n",
            "\n",
            "val \t epoch: 46  ,idx: 191   ,miou:   0.917,maxiou: 0.954    ,miniou: 0.845    ,mdice: 0.937   ,maxdice: 0.960   ,mindice: 0.896   \n",
            "\n",
            "train \t epoch: 47  ,idx: 383   ,loss: 0.004   ,miou:   0.913,maxiou: 0.946    ,miniou: 0.847    ,mdice: 0.934   ,maxdice: 0.953   ,mindice: 0.901   \n",
            "\n",
            "val \t epoch: 47  ,idx: 191   ,miou:   0.918,maxiou: 0.959    ,miniou: 0.780    ,mdice: 0.938   ,maxdice: 0.967   ,mindice: 0.871   \n",
            "\n",
            "train \t epoch: 48  ,idx: 383   ,loss: 0.004   ,miou:   0.914,maxiou: 0.949    ,miniou: 0.836    ,mdice: 0.934   ,maxdice: 0.955   ,mindice: 0.890   \n",
            "\n",
            "val \t epoch: 48  ,idx: 191   ,miou:   0.916,maxiou: 0.957    ,miniou: 0.847    ,mdice: 0.936   ,maxdice: 0.962   ,mindice: 0.899   \n",
            "\n",
            "train \t epoch: 49  ,idx: 383   ,loss: 0.004   ,miou:   0.910,maxiou: 0.945    ,miniou: 0.741    ,mdice: 0.931   ,maxdice: 0.952   ,mindice: 0.829   \n",
            "\n",
            "val \t epoch: 49  ,idx: 191   ,miou:   0.916,maxiou: 0.953    ,miniou: 0.835    ,mdice: 0.937   ,maxdice: 0.958   ,mindice: 0.897   \n",
            "\n",
            "train \t epoch: 50  ,idx: 383   ,loss: 0.004   ,miou:   0.916,maxiou: 0.951    ,miniou: 0.854    ,mdice: 0.936   ,maxdice: 0.952   ,mindice: 0.904   \n",
            "\n",
            "val \t epoch: 50  ,idx: 191   ,miou:   0.918,maxiou: 0.964    ,miniou: 0.816    ,mdice: 0.938   ,maxdice: 0.962   ,mindice: 0.888   \n",
            "\n",
            "train \t epoch: 51  ,idx: 383   ,loss: 0.005   ,miou:   0.905,maxiou: 0.949    ,miniou: 0.590    ,mdice: 0.926   ,maxdice: 0.957   ,mindice: 0.707   \n",
            "\n",
            "val \t epoch: 51  ,idx: 191   ,miou:   0.802,maxiou: 0.956    ,miniou: 0.000    ,mdice: 0.835   ,maxdice: 0.958   ,mindice: 0.001   \n",
            "\n",
            "train \t epoch: 52  ,idx: 383   ,loss: 0.004   ,miou:   0.906,maxiou: 0.946    ,miniou: 0.751    ,mdice: 0.927   ,maxdice: 0.950   ,mindice: 0.828   \n",
            "\n",
            "val \t epoch: 52  ,idx: 191   ,miou:   0.915,maxiou: 0.958    ,miniou: 0.692    ,mdice: 0.934   ,maxdice: 0.960   ,mindice: 0.808   \n",
            "\n",
            "train \t epoch: 53  ,idx: 383   ,loss: 0.004   ,miou:   0.921,maxiou: 0.949    ,miniou: 0.862    ,mdice: 0.940   ,maxdice: 0.958   ,mindice: 0.909   \n",
            "\n",
            "val \t epoch: 53  ,idx: 191   ,miou:   0.928,maxiou: 0.962    ,miniou: 0.866    ,mdice: 0.946   ,maxdice: 0.967   ,mindice: 0.914   \n",
            "\n",
            "train \t epoch: 54  ,idx: 383   ,loss: 0.004   ,miou:   0.919,maxiou: 0.952    ,miniou: 0.720    ,mdice: 0.938   ,maxdice: 0.956   ,mindice: 0.795   \n",
            "\n",
            "val \t epoch: 54  ,idx: 191   ,miou:   0.927,maxiou: 0.960    ,miniou: 0.840    ,mdice: 0.944   ,maxdice: 0.965   ,mindice: 0.901   \n",
            "\n",
            "train \t epoch: 55  ,idx: 383   ,loss: 0.003   ,miou:   0.926,maxiou: 0.954    ,miniou: 0.849    ,mdice: 0.943   ,maxdice: 0.960   ,mindice: 0.890   \n",
            "\n",
            "val \t epoch: 55  ,idx: 191   ,miou:   0.932,maxiou: 0.966    ,miniou: 0.868    ,mdice: 0.948   ,maxdice: 0.970   ,mindice: 0.908   \n",
            "\n",
            "train \t epoch: 56  ,idx: 383   ,loss: 0.003   ,miou:   0.928,maxiou: 0.958    ,miniou: 0.880    ,mdice: 0.945   ,maxdice: 0.961   ,mindice: 0.915   \n",
            "\n",
            "val \t epoch: 56  ,idx: 191   ,miou:   0.933,maxiou: 0.964    ,miniou: 0.872    ,mdice: 0.949   ,maxdice: 0.969   ,mindice: 0.918   \n",
            "\n",
            "train \t epoch: 57  ,idx: 383   ,loss: 0.003   ,miou:   0.928,maxiou: 0.957    ,miniou: 0.750    ,mdice: 0.945   ,maxdice: 0.961   ,mindice: 0.847   \n",
            "\n",
            "val \t epoch: 57  ,idx: 191   ,miou:   0.832,maxiou: 0.953    ,miniou: 0.280    ,mdice: 0.862   ,maxdice: 0.954   ,mindice: 0.391   \n",
            "\n",
            "train \t epoch: 58  ,idx: 383   ,loss: 0.004   ,miou:   0.910,maxiou: 0.954    ,miniou: 0.607    ,mdice: 0.930   ,maxdice: 0.956   ,mindice: 0.730   \n",
            "\n",
            "val \t epoch: 58  ,idx: 191   ,miou:   0.931,maxiou: 0.965    ,miniou: 0.848    ,mdice: 0.947   ,maxdice: 0.970   ,mindice: 0.905   \n",
            "\n",
            "train \t epoch: 59  ,idx: 383   ,loss: 0.003   ,miou:   0.930,maxiou: 0.958    ,miniou: 0.867    ,mdice: 0.947   ,maxdice: 0.963   ,mindice: 0.913   \n",
            "\n",
            "val \t epoch: 59  ,idx: 191   ,miou:   0.937,maxiou: 0.968    ,miniou: 0.870    ,mdice: 0.952   ,maxdice: 0.971   ,mindice: 0.921   \n",
            "\n",
            "train \t epoch: 60  ,idx: 383   ,loss: 0.003   ,miou:   0.935,maxiou: 0.958    ,miniou: 0.871    ,mdice: 0.950   ,maxdice: 0.964   ,mindice: 0.915   \n",
            "\n",
            "val \t epoch: 60  ,idx: 191   ,miou:   0.941,maxiou: 0.965    ,miniou: 0.897    ,mdice: 0.954   ,maxdice: 0.970   ,mindice: 0.931   \n",
            "\n",
            "train \t epoch: 61  ,idx: 383   ,loss: 0.003   ,miou:   0.936,maxiou: 0.962    ,miniou: 0.897    ,mdice: 0.951   ,maxdice: 0.964   ,mindice: 0.925   \n",
            "\n",
            "val \t epoch: 61  ,idx: 191   ,miou:   0.941,maxiou: 0.967    ,miniou: 0.891    ,mdice: 0.955   ,maxdice: 0.971   ,mindice: 0.923   \n",
            "\n",
            "train \t epoch: 62  ,idx: 383   ,loss: 0.003   ,miou:   0.936,maxiou: 0.962    ,miniou: 0.850    ,mdice: 0.951   ,maxdice: 0.965   ,mindice: 0.892   \n",
            "\n",
            "val \t epoch: 62  ,idx: 191   ,miou:   0.931,maxiou: 0.972    ,miniou: 0.830    ,mdice: 0.948   ,maxdice: 0.969   ,mindice: 0.899   \n",
            "\n",
            "train \t epoch: 63  ,idx: 383   ,loss: 0.003   ,miou:   0.936,maxiou: 0.966    ,miniou: 0.883    ,mdice: 0.951   ,maxdice: 0.966   ,mindice: 0.919   \n",
            "\n",
            "val \t epoch: 63  ,idx: 191   ,miou:   0.937,maxiou: 0.968    ,miniou: 0.889    ,mdice: 0.952   ,maxdice: 0.968   ,mindice: 0.927   \n",
            "\n",
            "train \t epoch: 64  ,idx: 383   ,loss: 0.003   ,miou:   0.937,maxiou: 0.960    ,miniou: 0.884    ,mdice: 0.952   ,maxdice: 0.965   ,mindice: 0.924   \n",
            "\n",
            "val \t epoch: 64  ,idx: 191   ,miou:   0.940,maxiou: 0.972    ,miniou: 0.887    ,mdice: 0.954   ,maxdice: 0.970   ,mindice: 0.929   \n",
            "\n",
            "train \t epoch: 65  ,idx: 383   ,loss: 0.003   ,miou:   0.937,maxiou: 0.962    ,miniou: 0.901    ,mdice: 0.952   ,maxdice: 0.966   ,mindice: 0.926   \n",
            "\n",
            "val \t epoch: 65  ,idx: 191   ,miou:   0.837,maxiou: 0.960    ,miniou: 0.000    ,mdice: 0.868   ,maxdice: 0.964   ,mindice: 0.023   \n",
            "\n",
            "train \t epoch: 66  ,idx: 383   ,loss: 0.004   ,miou:   0.920,maxiou: 0.961    ,miniou: 0.560    ,mdice: 0.935   ,maxdice: 0.960   ,mindice: 0.685   \n",
            "\n",
            "val \t epoch: 66  ,idx: 191   ,miou:   0.940,maxiou: 0.970    ,miniou: 0.859    ,mdice: 0.954   ,maxdice: 0.971   ,mindice: 0.908   \n",
            "\n",
            "train \t epoch: 67  ,idx: 383   ,loss: 0.003   ,miou:   0.942,maxiou: 0.969    ,miniou: 0.888    ,mdice: 0.954   ,maxdice: 0.966   ,mindice: 0.914   \n",
            "\n",
            "val \t epoch: 67  ,idx: 191   ,miou:   0.949,maxiou: 0.972    ,miniou: 0.893    ,mdice: 0.960   ,maxdice: 0.975   ,mindice: 0.932   \n",
            "\n",
            "train \t epoch: 68  ,idx: 383   ,loss: 0.003   ,miou:   0.945,maxiou: 0.965    ,miniou: 0.900    ,mdice: 0.957   ,maxdice: 0.968   ,mindice: 0.935   \n",
            "\n",
            "val \t epoch: 68  ,idx: 191   ,miou:   0.950,maxiou: 0.971    ,miniou: 0.915    ,mdice: 0.961   ,maxdice: 0.973   ,mindice: 0.943   \n",
            "\n",
            "train \t epoch: 69  ,idx: 383   ,loss: 0.002   ,miou:   0.947,maxiou: 0.968    ,miniou: 0.898    ,mdice: 0.959   ,maxdice: 0.971   ,mindice: 0.939   \n",
            "\n",
            "val \t epoch: 69  ,idx: 191   ,miou:   0.946,maxiou: 0.971    ,miniou: 0.877    ,mdice: 0.958   ,maxdice: 0.975   ,mindice: 0.921   \n",
            "\n",
            "train \t epoch: 70  ,idx: 383   ,loss: 0.003   ,miou:   0.945,maxiou: 0.966    ,miniou: 0.898    ,mdice: 0.958   ,maxdice: 0.970   ,mindice: 0.926   \n",
            "\n",
            "val \t epoch: 70  ,idx: 191   ,miou:   0.947,maxiou: 0.973    ,miniou: 0.882    ,mdice: 0.959   ,maxdice: 0.977   ,mindice: 0.927   \n",
            "\n",
            "train \t epoch: 71  ,idx: 383   ,loss: 0.003   ,miou:   0.940,maxiou: 0.963    ,miniou: 0.746    ,mdice: 0.954   ,maxdice: 0.968   ,mindice: 0.799   \n",
            "\n",
            "val \t epoch: 71  ,idx: 191   ,miou:   0.946,maxiou: 0.971    ,miniou: 0.900    ,mdice: 0.958   ,maxdice: 0.974   ,mindice: 0.935   \n",
            "\n",
            "train \t epoch: 72  ,idx: 383   ,loss: 0.003   ,miou:   0.945,maxiou: 0.969    ,miniou: 0.864    ,mdice: 0.957   ,maxdice: 0.969   ,mindice: 0.904   \n",
            "\n",
            "val \t epoch: 72  ,idx: 191   ,miou:   0.944,maxiou: 0.972    ,miniou: 0.839    ,mdice: 0.957   ,maxdice: 0.974   ,mindice: 0.899   \n",
            "\n",
            "train \t epoch: 73  ,idx: 383   ,loss: 0.003   ,miou:   0.945,maxiou: 0.967    ,miniou: 0.902    ,mdice: 0.958   ,maxdice: 0.970   ,mindice: 0.933   \n",
            "\n",
            "val \t epoch: 73  ,idx: 191   ,miou:   0.943,maxiou: 0.971    ,miniou: 0.865    ,mdice: 0.957   ,maxdice: 0.975   ,mindice: 0.920   \n",
            "\n",
            "train \t epoch: 74  ,idx: 383   ,loss: 0.003   ,miou:   0.946,maxiou: 0.967    ,miniou: 0.908    ,mdice: 0.959   ,maxdice: 0.971   ,mindice: 0.937   \n",
            "\n",
            "val \t epoch: 74  ,idx: 191   ,miou:   0.945,maxiou: 0.973    ,miniou: 0.899    ,mdice: 0.957   ,maxdice: 0.974   ,mindice: 0.938   \n",
            "\n",
            "train \t epoch: 75  ,idx: 383   ,loss: 0.004   ,miou:   0.913,maxiou: 0.963    ,miniou: 0.474    ,mdice: 0.931   ,maxdice: 0.968   ,mindice: 0.629   \n",
            "\n",
            "val \t epoch: 75  ,idx: 191   ,miou:   0.945,maxiou: 0.972    ,miniou: 0.899    ,mdice: 0.958   ,maxdice: 0.973   ,mindice: 0.926   \n",
            "\n",
            "train \t epoch: 76  ,idx: 383   ,loss: 0.003   ,miou:   0.943,maxiou: 0.967    ,miniou: 0.841    ,mdice: 0.956   ,maxdice: 0.968   ,mindice: 0.895   \n",
            "\n",
            "val \t epoch: 76  ,idx: 191   ,miou:   0.952,maxiou: 0.978    ,miniou: 0.915    ,mdice: 0.963   ,maxdice: 0.979   ,mindice: 0.939   \n",
            "\n",
            "train \t epoch: 77  ,idx: 383   ,loss: 0.002   ,miou:   0.951,maxiou: 0.971    ,miniou: 0.887    ,mdice: 0.962   ,maxdice: 0.972   ,mindice: 0.933   \n",
            "\n",
            "val \t epoch: 77  ,idx: 191   ,miou:   0.953,maxiou: 0.975    ,miniou: 0.914    ,mdice: 0.963   ,maxdice: 0.978   ,mindice: 0.945   \n",
            "\n",
            "train \t epoch: 78  ,idx: 383   ,loss: 0.002   ,miou:   0.953,maxiou: 0.971    ,miniou: 0.919    ,mdice: 0.963   ,maxdice: 0.974   ,mindice: 0.948   \n",
            "\n",
            "val \t epoch: 78  ,idx: 191   ,miou:   0.952,maxiou: 0.975    ,miniou: 0.914    ,mdice: 0.963   ,maxdice: 0.978   ,mindice: 0.937   \n",
            "\n",
            "train \t epoch: 79  ,idx: 383   ,loss: 0.002   ,miou:   0.952,maxiou: 0.970    ,miniou: 0.910    ,mdice: 0.963   ,maxdice: 0.974   ,mindice: 0.943   \n",
            "\n",
            "val \t epoch: 79  ,idx: 191   ,miou:   0.920,maxiou: 0.967    ,miniou: 0.343    ,mdice: 0.938   ,maxdice: 0.973   ,mindice: 0.518   \n",
            "\n",
            "train \t epoch: 80  ,idx: 383   ,loss: 0.004   ,miou:   0.925,maxiou: 0.968    ,miniou: 0.640    ,mdice: 0.941   ,maxdice: 0.968   ,mindice: 0.730   \n",
            "\n",
            "val \t epoch: 80  ,idx: 191   ,miou:   0.945,maxiou: 0.971    ,miniou: 0.878    ,mdice: 0.958   ,maxdice: 0.976   ,mindice: 0.917   \n",
            "\n",
            "train \t epoch: 81  ,idx: 383   ,loss: 0.002   ,miou:   0.951,maxiou: 0.971    ,miniou: 0.917    ,mdice: 0.962   ,maxdice: 0.974   ,mindice: 0.944   \n",
            "\n",
            "val \t epoch: 81  ,idx: 191   ,miou:   0.957,maxiou: 0.979    ,miniou: 0.922    ,mdice: 0.966   ,maxdice: 0.977   ,mindice: 0.949   \n",
            "\n",
            "train \t epoch: 82  ,idx: 383   ,loss: 0.002   ,miou:   0.956,maxiou: 0.974    ,miniou: 0.907    ,mdice: 0.965   ,maxdice: 0.974   ,mindice: 0.937   \n",
            "\n",
            "val \t epoch: 82  ,idx: 191   ,miou:   0.890,maxiou: 0.974    ,miniou: 0.104    ,mdice: 0.913   ,maxdice: 0.973   ,mindice: 0.407   \n",
            "\n",
            "train \t epoch: 83  ,idx: 383   ,loss: 0.002   ,miou:   0.947,maxiou: 0.970    ,miniou: 0.852    ,mdice: 0.959   ,maxdice: 0.972   ,mindice: 0.895   \n",
            "\n",
            "val \t epoch: 83  ,idx: 191   ,miou:   0.958,maxiou: 0.978    ,miniou: 0.916    ,mdice: 0.966   ,maxdice: 0.980   ,mindice: 0.945   \n",
            "\n",
            "train \t epoch: 84  ,idx: 383   ,loss: 0.002   ,miou:   0.957,maxiou: 0.973    ,miniou: 0.907    ,mdice: 0.966   ,maxdice: 0.975   ,mindice: 0.944   \n",
            "\n",
            "val \t epoch: 84  ,idx: 191   ,miou:   0.961,maxiou: 0.977    ,miniou: 0.911    ,mdice: 0.969   ,maxdice: 0.980   ,mindice: 0.945   \n",
            "\n",
            "train \t epoch: 85  ,idx: 383   ,loss: 0.002   ,miou:   0.958,maxiou: 0.973    ,miniou: 0.912    ,mdice: 0.967   ,maxdice: 0.976   ,mindice: 0.943   \n",
            "\n",
            "val \t epoch: 85  ,idx: 191   ,miou:   0.960,maxiou: 0.980    ,miniou: 0.912    ,mdice: 0.968   ,maxdice: 0.980   ,mindice: 0.941   \n",
            "\n",
            "train \t epoch: 86  ,idx: 383   ,loss: 0.002   ,miou:   0.958,maxiou: 0.974    ,miniou: 0.907    ,mdice: 0.966   ,maxdice: 0.976   ,mindice: 0.938   \n",
            "\n",
            "val \t epoch: 86  ,idx: 191   ,miou:   0.958,maxiou: 0.976    ,miniou: 0.916    ,mdice: 0.967   ,maxdice: 0.980   ,mindice: 0.946   \n",
            "\n",
            "train \t epoch: 87  ,idx: 383   ,loss: 0.002   ,miou:   0.956,maxiou: 0.972    ,miniou: 0.887    ,mdice: 0.965   ,maxdice: 0.973   ,mindice: 0.929   \n",
            "\n",
            "val \t epoch: 87  ,idx: 191   ,miou:   0.957,maxiou: 0.983    ,miniou: 0.903    ,mdice: 0.966   ,maxdice: 0.982   ,mindice: 0.943   \n",
            "\n",
            "train \t epoch: 88  ,idx: 383   ,loss: 0.002   ,miou:   0.956,maxiou: 0.976    ,miniou: 0.915    ,mdice: 0.965   ,maxdice: 0.975   ,mindice: 0.946   \n",
            "\n",
            "val \t epoch: 88  ,idx: 191   ,miou:   0.957,maxiou: 0.976    ,miniou: 0.907    ,mdice: 0.966   ,maxdice: 0.979   ,mindice: 0.939   \n",
            "\n",
            "train \t epoch: 89  ,idx: 383   ,loss: 0.002   ,miou:   0.956,maxiou: 0.973    ,miniou: 0.905    ,mdice: 0.965   ,maxdice: 0.975   ,mindice: 0.942   \n",
            "\n",
            "val \t epoch: 89  ,idx: 191   ,miou:   0.869,maxiou: 0.973    ,miniou: 0.252    ,mdice: 0.889   ,maxdice: 0.975   ,mindice: 0.316   \n",
            "\n",
            "train \t epoch: 90  ,idx: 383   ,loss: 0.003   ,miou:   0.932,maxiou: 0.970    ,miniou: 0.539    ,mdice: 0.946   ,maxdice: 0.970   ,mindice: 0.671   \n",
            "\n",
            "val \t epoch: 90  ,idx: 191   ,miou:   0.955,maxiou: 0.980    ,miniou: 0.888    ,mdice: 0.964   ,maxdice: 0.980   ,mindice: 0.933   \n",
            "\n",
            "train \t epoch: 91  ,idx: 383   ,loss: 0.002   ,miou:   0.957,maxiou: 0.972    ,miniou: 0.918    ,mdice: 0.966   ,maxdice: 0.975   ,mindice: 0.939   \n",
            "\n",
            "val \t epoch: 91  ,idx: 191   ,miou:   0.963,maxiou: 0.981    ,miniou: 0.935    ,mdice: 0.970   ,maxdice: 0.981   ,mindice: 0.954   \n",
            "\n",
            "train \t epoch: 92  ,idx: 383   ,loss: 0.002   ,miou:   0.962,maxiou: 0.978    ,miniou: 0.901    ,mdice: 0.969   ,maxdice: 0.976   ,mindice: 0.942   \n",
            "\n",
            "val \t epoch: 92  ,idx: 191   ,miou:   0.965,maxiou: 0.983    ,miniou: 0.932    ,mdice: 0.971   ,maxdice: 0.983   ,mindice: 0.956   \n",
            "\n",
            "train \t epoch: 93  ,idx: 383   ,loss: 0.002   ,miou:   0.963,maxiou: 0.976    ,miniou: 0.905    ,mdice: 0.970   ,maxdice: 0.977   ,mindice: 0.943   \n",
            "\n",
            "val \t epoch: 93  ,idx: 191   ,miou:   0.966,maxiou: 0.983    ,miniou: 0.932    ,mdice: 0.972   ,maxdice: 0.983   ,mindice: 0.951   \n",
            "\n",
            "train \t epoch: 94  ,idx: 383   ,loss: 0.002   ,miou:   0.962,maxiou: 0.975    ,miniou: 0.907    ,mdice: 0.969   ,maxdice: 0.978   ,mindice: 0.945   \n",
            "\n",
            "val \t epoch: 94  ,idx: 191   ,miou:   0.964,maxiou: 0.982    ,miniou: 0.925    ,mdice: 0.970   ,maxdice: 0.982   ,mindice: 0.949   \n",
            "\n",
            "train \t epoch: 95  ,idx: 383   ,loss: 0.002   ,miou:   0.962,maxiou: 0.976    ,miniou: 0.916    ,mdice: 0.969   ,maxdice: 0.977   ,mindice: 0.950   \n",
            "\n",
            "val \t epoch: 95  ,idx: 191   ,miou:   0.962,maxiou: 0.983    ,miniou: 0.923    ,mdice: 0.969   ,maxdice: 0.982   ,mindice: 0.951   \n",
            "\n",
            "train \t epoch: 96  ,idx: 383   ,loss: 0.002   ,miou:   0.960,maxiou: 0.975    ,miniou: 0.915    ,mdice: 0.968   ,maxdice: 0.976   ,mindice: 0.949   \n",
            "\n",
            "val \t epoch: 96  ,idx: 191   ,miou:   0.960,maxiou: 0.980    ,miniou: 0.923    ,mdice: 0.968   ,maxdice: 0.981   ,mindice: 0.949   \n",
            "\n",
            "train \t epoch: 97  ,idx: 383   ,loss: 0.002   ,miou:   0.960,maxiou: 0.976    ,miniou: 0.903    ,mdice: 0.967   ,maxdice: 0.977   ,mindice: 0.898   \n",
            "\n",
            "val \t epoch: 97  ,idx: 191   ,miou:   0.957,maxiou: 0.977    ,miniou: 0.913    ,mdice: 0.966   ,maxdice: 0.979   ,mindice: 0.942   \n",
            "\n",
            "train \t epoch: 98  ,idx: 383   ,loss: 0.002   ,miou:   0.958,maxiou: 0.976    ,miniou: 0.917    ,mdice: 0.967   ,maxdice: 0.977   ,mindice: 0.942   \n",
            "\n",
            "val \t epoch: 98  ,idx: 191   ,miou:   0.955,maxiou: 0.976    ,miniou: 0.892    ,mdice: 0.965   ,maxdice: 0.979   ,mindice: 0.934   \n",
            "\n",
            "train \t epoch: 99  ,idx: 383   ,loss: 0.002   ,miou:   0.959,maxiou: 0.974    ,miniou: 0.913    ,mdice: 0.967   ,maxdice: 0.975   ,mindice: 0.947   \n",
            "\n",
            "val \t epoch: 99  ,idx: 191   ,miou:   0.956,maxiou: 0.977    ,miniou: 0.912    ,mdice: 0.966   ,maxdice: 0.980   ,mindice: 0.948   \n",
            "\n"
          ]
        }
      ],
      "source": [
        "file3='/content/drive/MyDrive/result/train/train_7m_Unet_res_myself_pool_change.txt'\n",
        "file4='/content/drive/MyDrive/result/test/test_7m_Unet_res_myself_pool_change.txt'\n",
        "path2='/content/drive/MyDrive/result/checkpoints/train_7m_Unet_res_myself_pool'\n",
        "train2.fit(file3,file4,path2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pic2=next(iter(dataloaders['val']))\n",
        "pth2=model.load_state_dict(torch.load(os.path.join(path2,'_%d.pth'%(num_epoch-1)))).to(device)\n",
        "y2=pth2(pic2).cpu()\n",
        "img2_y=torch.squeeze(y2).numpy()\n",
        "plt.imshow(img2_y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_enN2KdGSLb"
      },
      "source": [
        "## 模型数据3\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i94h3wR4HBvR",
        "outputId": "1688f69a-369d-4f82-f0f4-64910140715c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 224, 224]           1,792\n",
            "       BatchNorm2d-2         [-1, 64, 224, 224]             128\n",
            "              ReLU-3         [-1, 64, 224, 224]               0\n",
            "            Conv2d-4         [-1, 64, 224, 224]          36,928\n",
            "       BatchNorm2d-5         [-1, 64, 224, 224]             128\n",
            "              ReLU-6         [-1, 64, 224, 224]               0\n",
            "         MaxPool2d-7         [-1, 64, 112, 112]               0\n",
            "            Conv2d-8        [-1, 128, 112, 112]          73,856\n",
            "       BatchNorm2d-9        [-1, 128, 112, 112]             256\n",
            "             ReLU-10        [-1, 128, 112, 112]               0\n",
            "           Conv2d-11        [-1, 128, 112, 112]         147,584\n",
            "      BatchNorm2d-12        [-1, 128, 112, 112]             256\n",
            "             ReLU-13        [-1, 128, 112, 112]               0\n",
            "        MaxPool2d-14          [-1, 128, 56, 56]               0\n",
            "           Conv2d-15          [-1, 256, 56, 56]         295,168\n",
            "      BatchNorm2d-16          [-1, 256, 56, 56]             512\n",
            "             ReLU-17          [-1, 256, 56, 56]               0\n",
            "           Conv2d-18          [-1, 256, 56, 56]         590,080\n",
            "      BatchNorm2d-19          [-1, 256, 56, 56]             512\n",
            "             ReLU-20          [-1, 256, 56, 56]               0\n",
            "        MaxPool2d-21          [-1, 256, 28, 28]               0\n",
            "           Conv2d-22          [-1, 512, 28, 28]       1,180,160\n",
            "      BatchNorm2d-23          [-1, 512, 28, 28]           1,024\n",
            "             ReLU-24          [-1, 512, 28, 28]               0\n",
            "           Conv2d-25          [-1, 512, 28, 28]       2,359,808\n",
            "      BatchNorm2d-26          [-1, 512, 28, 28]           1,024\n",
            "             ReLU-27          [-1, 512, 28, 28]               0\n",
            "        MaxPool2d-28          [-1, 512, 14, 14]               0\n",
            "           Conv2d-29         [-1, 1024, 14, 14]       4,719,616\n",
            "      BatchNorm2d-30         [-1, 1024, 14, 14]           2,048\n",
            "             ReLU-31         [-1, 1024, 14, 14]               0\n",
            "           Conv2d-32         [-1, 1024, 14, 14]       9,438,208\n",
            "      BatchNorm2d-33         [-1, 1024, 14, 14]           2,048\n",
            "             ReLU-34         [-1, 1024, 14, 14]               0\n",
            "  ConvTranspose2d-35          [-1, 512, 28, 28]       2,097,664\n",
            "           Conv2d-36          [-1, 512, 28, 28]       4,719,104\n",
            "      BatchNorm2d-37          [-1, 512, 28, 28]           1,024\n",
            "             ReLU-38          [-1, 512, 28, 28]               0\n",
            "           Conv2d-39          [-1, 512, 28, 28]       2,359,808\n",
            "      BatchNorm2d-40          [-1, 512, 28, 28]           1,024\n",
            "             ReLU-41          [-1, 512, 28, 28]               0\n",
            "  ConvTranspose2d-42          [-1, 256, 56, 56]         524,544\n",
            "           Conv2d-43          [-1, 256, 56, 56]       1,179,904\n",
            "      BatchNorm2d-44          [-1, 256, 56, 56]             512\n",
            "             ReLU-45          [-1, 256, 56, 56]               0\n",
            "           Conv2d-46          [-1, 256, 56, 56]         590,080\n",
            "      BatchNorm2d-47          [-1, 256, 56, 56]             512\n",
            "             ReLU-48          [-1, 256, 56, 56]               0\n",
            "  ConvTranspose2d-49        [-1, 128, 112, 112]         131,200\n",
            "           Conv2d-50        [-1, 128, 112, 112]         295,040\n",
            "      BatchNorm2d-51        [-1, 128, 112, 112]             256\n",
            "             ReLU-52        [-1, 128, 112, 112]               0\n",
            "           Conv2d-53        [-1, 128, 112, 112]         147,584\n",
            "      BatchNorm2d-54        [-1, 128, 112, 112]             256\n",
            "             ReLU-55        [-1, 128, 112, 112]               0\n",
            "  ConvTranspose2d-56         [-1, 64, 224, 224]          32,832\n",
            "           Conv2d-57         [-1, 64, 224, 224]          73,792\n",
            "      BatchNorm2d-58         [-1, 64, 224, 224]             128\n",
            "             ReLU-59         [-1, 64, 224, 224]               0\n",
            "           Conv2d-60         [-1, 64, 224, 224]          36,928\n",
            "      BatchNorm2d-61         [-1, 64, 224, 224]             128\n",
            "             ReLU-62         [-1, 64, 224, 224]               0\n",
            "           Conv2d-63          [-1, 1, 224, 224]              65\n",
            "================================================================\n",
            "Total params: 31,043,521\n",
            "Trainable params: 31,043,521\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 618.24\n",
            "Params size (MB): 118.42\n",
            "Estimated Total Size (MB): 737.24\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "model3=Unet(n_class=1)\n",
        "#model=Unet(n_class=1)\n",
        "model3.to(device)\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model3.parameters())\n",
        "\n",
        "train3=train_model_local(model3)\n",
        "train3.summarys(input_size=(3,224,224))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_5hAryo8HCLb"
      },
      "outputs": [],
      "source": [
        "train3.compile(dataloaders,criterion,optimizer,num_epoch,batch_size,train_path,val_path,device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z1qdCUbeHCbN"
      },
      "outputs": [],
      "source": [
        "file5='/content/drive/MyDrive/result/train/train_7m_Unet_change.txt'\n",
        "file6='/content/drive/MyDrive/result/test/test_7m_Unet_change.txt'\n",
        "path3='/content/drive/MyDrive/result/checkpoints/train_7m_Unet_change'\n",
        "train3.fit(file5,file6,path3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pic3=next(iter(dataloaders['val']))\n",
        "pth3=model.load_state_dict(torch.load(os.path.join(path3,'_%d.pth'%(num_epoch-1)))).to(device)\n",
        "y3=pth3(pic3).cpu()\n",
        "img3_y=torch.squeeze(y3).numpy()\n",
        "plt.imshow(img3_y)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "f1Z5R8a9ItS6"
      ],
      "machine_shape": "hm",
      "name": "main_unet",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
